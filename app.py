from flask import Flask, request, jsonify
from flask_cors import CORS
import requests
import os
import json
import io
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload, MediaIoBaseUpload, MediaFileUpload
from datetime import datetime, timedelta
import pandas as pdIF
import matplotlib.pyplot as plt
from matplotlib.backends.backend_pdf import PdfPages
import tempfile
import numpy as np
import re
import time
import base64

import json

from math import pi
from reportlab.lib.units import cm
import pandas as pd
import os
import traceback # NOVO: Para depura√ß√£o detalhada

app = Flask(__name__)
CORS(app, resources={r"/*": {"origins": ["https://gestor.thehrkey.tech"]}}, supports_credentials=True)

@app.after_request
def aplicar_cors(response):
    response.headers["Access-Control-Allow-Origin"] = "https://gestor.thehrkey.tech"
    response.headers["Access-Control-Allow-Headers"] = "Content-Type,Authorization"
    response.headers["Access-Control-Allow-Methods"] = "GET,POST,OPTIONS"
    return response


# === Fun√ß√µes de c√°lculo ===

def calcular_percentuais(respostas_dict):
    print("üì• [DEBUG] Entrou em calcular_percentuais")
    print(f"üì• [DEBUG] Respostas recebidas: {len(respostas_dict)} itens. Exemplo Q01: {respostas_dict.get('Q01', 'N/A')}")

    total_por_arquetipo = {a: 0 for a in arquetipos}
    max_por_arquetipo = {a: 0 for a in arquetipos}

    for cod_pergunta in perguntas: # Itera por "Q01", "Q02", ..., "Q49"
        raw_nota = respostas_dict.get(cod_pergunta, "") # Pega a nota bruta (string)
        
        try:
            # Tenta converter a nota para float e depois para int
            nota = int(round(float(raw_nota)))
            
            # Valida se a nota est√° no intervalo esperado (1 a 6)
            if nota < 1 or nota > 6:
                print(f"‚ö†Ô∏è Nota fora do intervalo ignorada para {cod_pergunta}: '{raw_nota}' -> {nota}")
                continue # Pula para a pr√≥xima pergunta se a nota for inv√°lida

            # Para cada arqu√©tipo, constr√≥i a chave e busca na matriz
            for arq_nome in arquetipos:
                # Constr√≥i a chave no formato "ARQUETIPO_NOME_NOTA_COD_PERGUNTA"
                # Exemplo: "Formador2Q01"
                chave = f"{arq_nome}{nota}{cod_pergunta}"
                
                # Busca a linha correspondente na matriz
                # 'matriz' √© o DataFrame carregado do seu Excel
                linha_matriz = matriz[matriz["CHAVE"] == chave]

                if not linha_matriz.empty:
                    # Se a chave for encontrada, extrai os pontos obtidos e m√°ximos
                    pontos_obtidos = linha_matriz["PONTOS_OBTIDOS"].values[0]
                    pontos_maximos = linha_matriz["PONTOS_MAXIMOS"].values[0]

                    # Acumula os pontos para o arqu√©tipo atual
                    total_por_arquetipo[arq_nome] += pontos_obtidos
                    max_por_arquetipo[arq_nome] += pontos_maximos
                else:
                    # Mensagem de depura√ß√£o se a chave n√£o for encontrada
                    print(f"‚ö†Ô∏è Chave '{chave}' n√£o encontrada na matriz para {cod_pergunta} com nota {nota} e arqu√©tipo {arq_nome}.")

        except ValueError:
            # Captura erro se 'raw_nota' n√£o puder ser convertido para n√∫mero
            print(f"‚ö†Ô∏è Erro de convers√£o para n√∫mero em {cod_pergunta}: '{raw_nota}' n√£o √© um n√∫mero v√°lido.")
            continue
        except Exception as e:
            # Captura qualquer outro erro inesperado durante o processamento da pergunta
            print(f"‚ö†Ô∏è Erro inesperado ao processar {cod_pergunta} com nota '{raw_nota}': {e}")
            continue

    percentuais = {}
    for arq_nome in arquetipos:
        # Calcula o percentual apenas se houver pontos m√°ximos para evitar divis√£o por zero
        if max_por_arquetipo[arq_nome] > 0:
            percentuais[arq_nome] = round((total_por_arquetipo[arq_nome] / max_por_arquetipo[arq_nome]) * 100, 1)
        else:
            percentuais[arq_nome] = 0 # Se n√£o houver pontos m√°ximos, o percentual √© 0

    print(f"üìä [DEBUG] Percentuais calculados: {percentuais}")
    return percentuais


def calcular_percentuais_equipes(lista_de_respostas):
    print("üì• [DEBUG] Entrou em calcular_percentuais_equipes")
    print(f"üì• [DEBUG] Total de avalia√ß√µes de equipe recebidas: {len(lista_de_respostas)}")

    soma_percentuais_por_arquetipo = {a: 0 for a in arquetipos}
    total_avaliacoes_validas = 0

    for respostas_dict_membro in lista_de_respostas:
        # Verifica se o dicion√°rio de respostas do membro n√£o est√° vazio
        if not respostas_dict_membro:
            print("‚ö†Ô∏è Dicion√°rio de respostas de um membro da equipe est√° vazio, ignorando.")
            continue
        
        # Chama a fun√ß√£o calcular_percentuais para cada conjunto de respostas de um membro
        percentuais_individuais = calcular_percentuais(respostas_dict_membro)
        
        # Verifica se o c√°lculo individual retornou percentuais v√°lidos
        if percentuais_individuais:
            for arq_nome in arquetipos:
                # Soma os percentuais individuais para cada arqu√©tipo
                soma_percentuais_por_arquetipo[arq_nome] += percentuais_individuais.get(arq_nome, 0)
            total_avaliacoes_validas += 1
        else:
            print("‚ö†Ô∏è C√°lculo individual de percentuais retornou vazio para um membro da equipe. N√£o ser√° inclu√≠do na m√©dia.")

    percentuais_medios = {}
    if total_avaliacoes_validas == 0:
        print("‚ö†Ô∏è Nenhuma avalia√ß√£o de equipe v√°lida para calcular a m√©dia. Retornando zeros.")
        return {a: 0 for a in arquetipos} # Retorna todos os percentuais como 0 se n√£o houver avalia√ß√µes v√°lidas

    for arq_nome in arquetipos:
        # Calcula a m√©dia dos percentuais para cada arqu√©tipo
        percentuais_medios[arq_nome] = round(soma_percentuais_por_arquetipo[arq_nome] / total_avaliacoes_validas, 1)

    print(f"üìä [DEBUG] Percentuais m√©dios da equipe calculados: {percentuais_medios}")
    return percentuais_medios


# NOVO: Configura√ß√£o global do Supabase (manter este bloco)
SUPABASE_REST_URL = os.environ.get("SUPABASE_REST_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY")

# Verifica se as vari√°veis de ambiente foram carregadas
if not SUPABASE_REST_URL or not SUPABASE_KEY:
    print("ERRO: Vari√°veis de ambiente SUPABASE_REST_URL ou SUPABASE_KEY n√£o configuradas. Verifique suas configura√ß√µes no Render.")
else:
    print("‚úÖ Credenciais Supabase carregadas com sucesso.")

# ‚úÖ Carrega a matriz de pontua√ß√£o de arqu√©tipos (manter estas linhas)
matriz = pd.read_excel("TABELA_GERAL_ARQUETIPOS_COM_CHAVE.xlsx")
print("üìÑ Matriz com chave carregada. Total de linhas:", len(matriz))

# ‚úÖ Lista de arqu√©tipos reconhecidos na matriz (manter estas linhas)
arquetipos = ["Formador", "Resoluto", "Cuidativo", "Consultivo", "Imperativo", "Prescritivo"] # Mantenha a lista expl√≠cita que voc√™ me deu
# Se voc√™ quiser que o c√≥digo determine os arqu√©tipos da matriz, use a linha original:
# arquetipos = sorted(list(set([a[:3] for a in matriz.columns if len(a) == 6 and a[3:].isdigit()])))

# ‚úÖ Lista de perguntas v√°lidas (manter esta linha)
perguntas = [f"Q{str(i).zfill(2)}" for i in range(1, 50)]

def extrair_valor(matriz_df, cod, nota, arquetipos_list):
    """
    Extrai informa√ß√µes de tend√™ncia e percentual da matriz_df
    com base no c√≥digo da quest√£o e na nota.
    """
    try:
        nota = int(round(float(nota)))
        if nota < 1 or nota > 6:
            return None
    except (ValueError, TypeError):
        return None

    for arq_item in arquetipos_list:
        chave = f"{arq_item}{nota}{cod}"
        linha = matriz_df[matriz_df["CHAVE"] == chave]
        if not linha.empty:
            percentual = round(float(linha['% Tend√™ncia'].values[0]) * 100, 1)
            return {
                "tendencia": linha['Tend√™ncia'].values[0],
                "percentual": percentual,
                "afirmacao": linha['AFIRMACAO'].values[0]
            }
    return None

def salvar_relatorio_analitico_no_supabase(dados_ia, empresa, codrodada, emailLider, nome_arquivo):
    """
    Salva os dados gerados do relat√≥rio anal√≠tico no Supabase.
    """
    if not SUPABASE_REST_URL or not SUPABASE_KEY:
        print("‚ùå N√£o foi poss√≠vel salvar o relat√≥rio anal√≠tico no Supabase: Vari√°veis de ambiente n√£o configuradas.")
        return

    # Ajuste o nome da tabela no Supabase se for diferente.
    # Esta tabela deve ser para os dados do relat√≥rio anal√≠tico por quest√£o.
    url = f"{SUPABASE_REST_URL}/relatorios_analiticos_hrkey" # Sugest√£o de nome de tabela
    headers = {
        "Content-Type": "application/json",
        "apikey": SUPABASE_KEY,
        "Authorization": f"Bearer {SUPABASE_KEY}" # Use a chave de servi√ßo para escrita se for o caso
    }

    payload = {
        "empresa": empresa,
        "codrodada": codrodada,
        "emaillider": emailLider,
        "dados_json": dados_ia, # Os dados JSON completos do relat√≥rio anal√≠tico
        "nome_arquivo": nome_arquivo,
        "data_criacao": datetime.now().isoformat()
    }

    try:
        response = requests.post(url, headers=headers, json=payload, timeout=30)
        response.raise_for_status() # Lan√ßa um erro para status de resposta HTTP ruins (4xx ou 5xx)
        print("‚úÖ JSON do relat√≥rio anal√≠tico salvo no Supabase com sucesso.")
    except requests.exceptions.RequestException as e:
        print(f"‚ùå Erro ao salvar JSON do relat√≥rio anal√≠tico no Supabase: {e}")
        if hasattr(response, 'status_code') and hasattr(response, 'text'):
            print(f"Detalhes da resposta do Supabase: Status {response.status_code} - {response.text}")
        else:
            print("N√£o foi poss√≠vel obter detalhes da resposta do Supabase.")


def salvar_json_ia_no_drive(dados, nome_base, service, id_lider):
    from io import BytesIO
    import json
    from googleapiclient.http import MediaIoBaseUpload

    nome_json = f"IA_{nome_base}.json"

    # Verifica ou cria a subpasta 'ia_json' dentro da pasta do l√≠der
    def buscar_ou_criar_pasta(nome, pai, service):
        query = f"'{pai}' in parents and name='{nome}' and mimeType='application/vnd.google-apps.folder' and trashed=false"
        resultado = service.files().list(q=query, fields="files(id)").execute().get("files", [])
        if resultado:
            return resultado[0]["id"]
        else:
            metadata = {"name": nome, "parents": [pai], "mimeType": "application/vnd.google-apps.folder"}
            pasta = service.files().create(body=metadata, fields="id").execute()
            return pasta["id"]

    id_subpasta = buscar_ou_criar_pasta("ia_json", id_lider, service)

    conteudo_bytes = BytesIO(json.dumps(dados, indent=2, ensure_ascii=False).encode("utf-8"))
    media = MediaIoBaseUpload(conteudo_bytes, mimetype="application/json")

    metadata = {"name": nome_json, "parents": [id_subpasta]}
    service.files().create(body=metadata, media_body=media, fields="id").execute()
    print(f"‚úÖ JSON IA salvo no Drive: {nome_json}")






# Carrega o dicion√°rio de arqu√©tipos dominantes por quest√£o
with open("arquetipos_dominantes_por_questao.json", encoding="utf-8") as f:
    arquetipos_dominantes = json.load(f)


# ‚úÖ Lista dos c√≥digos das 49 perguntas
perguntas = [f"Q{str(i).zfill(2)}" for i in range(1, 50)]

# ‚úÖ Carrega a matriz de c√°lculo com os arqu√©tipos reais da planilha
matriz = pd.read_excel("TABELA_GERAL_ARQUETIPOS_COM_CHAVE.xlsx")
arquetipos = sorted(matriz["ARQUETIPO"].unique())

# üîê Autentica√ß√£o Google Drive
SCOPES = ['https://www.googleapis.com/auth/drive']
creds = service_account.Credentials.from_service_account_info(
    json.loads(os.environ.get("GOOGLE_APPLICATION_CREDENTIALS")),
    scopes=SCOPES
)
service = build('drive', 'v3', credentials=creds)
PASTA_RAIZ = "1ekQKwPchEN_fO4AK0eyDd_JID5YO3hAF"

# üöÄ App Flask

@app.route("/")
def home():
    return "üîÅ API V2 pronta para uso com leitura no Google Drive."

def garantir_pasta(nome, id_pai):
    resultado = service.files().list(
        q=f"'{id_pai}' in parents and name = '{nome}' and mimeType = 'application/vnd.google-apps.folder' and trashed = false",
        fields="files(id)").execute()
    arquivos = resultado.get("files", [])
    if arquivos:
        return arquivos[0]["id"]
    else:
        pasta_metadata = {
            "name": nome,
            "mimeType": "application/vnd.google-apps.folder",
            "parents": [id_pai]
        }
        nova_pasta = service.files().create(body=pasta_metadata, fields="id").execute()
        return nova_pasta["id"]




@app.route("/gerar-relatorio-json", methods=["POST", "OPTIONS"])
def gerar_relatorio_json():
    if request.method == "OPTIONS":
        response = jsonify({'status': 'CORS preflight OK'})
        response.headers["Access-Control-Allow-Origin"] = "https://gestor.thehrkey.tech"
        response.headers["Access-Control-Allow-Headers"] = "Content-Type,Authorization"
        response.headers["Access-Control-Allow-Methods"] = "GET,POST,OPTIONS"
        return response

    try:
        dados = request.get_json()
        empresa = dados.get("empresa")
        print("üîé empresa recebida:", empresa)
        codrodada = dados.get("codrodada")
        email_lider = dados.get("emailLider")

        if not all([empresa, codrodada, email_lider]):
            return jsonify({"erro": "Campos obrigat√≥rios ausentes."}), 400

        def buscar_id_pasta(nome_pasta, id_pasta_mae):
            query = f"'{id_pasta_mae}' in parents and name = '{nome_pasta}' and mimeType = 'application/vnd.google-apps.folder' and trashed = false"
            resultados = service.files().list(q=query, fields="files(id, name)").execute()
            arquivos = resultados.get('files', [])
            return arquivos[0]['id'] if arquivos else None

        try:
            empresa_id = buscar_id_pasta(empresa, PASTA_RAIZ)
            print("üß© empresa_id:", empresa_id)
        
            rodada_id = buscar_id_pasta(codrodada, empresa_id)
            print("üß© rodada_id:", rodada_id)
        
            lider_id = buscar_id_pasta(email_lider, rodada_id)
            print("üß© lider_id:", lider_id)
        except Exception as e:
            print("‚ùå ERRO AO BUSCAR IDs:", str(e))
            raise


        if not lider_id:
            return jsonify({"erro": f"Pasta do l√≠der '{email_lider}' n√£o encontrada."}), 404
        
        # üßπ Remove relat√≥rios consolidados antigos antes de ler os arquivos
        antigos = service.files().list(
            q=f"'{lider_id}' in parents and name contains 'relatorio_consolidado_' and trashed = false and mimeType = 'application/json'",
            fields="files(id)").execute().get("files", [])

        for arq in antigos:
            service.files().delete(fileId=arq["id"]).execute()

        # üîç L√™ os arquivos de auto e equipe
        query = f"'{lider_id}' in parents and (mimeType = 'application/json' or mimeType = 'text/plain') and trashed = false"
        arquivos = service.files().list(q=query, fields="files(id, name)").execute().get('files', [])

        auto = None
        equipe = []

        for arquivo in arquivos:
            nome = arquivo['name']
            file_id = arquivo['id']

            # ‚ö†Ô∏è Ignorar relat√≥rios j√° consolidados de microambiente
            if nome.lower().startswith("relatorio_microambiente_"):
                continue

            request_drive = service.files().get_media(fileId=file_id)
            fh = io.BytesIO()
            downloader = MediaIoBaseDownload(fh, request_drive)
            done = False
            while not done:
                status, done = downloader.next_chunk()

            fh.seek(0)
            conteudo = json.load(fh)
            tipo = conteudo.get("tipo", "").lower()

            # üö´ Ignorar qualquer coisa de microambiente (campo tipo ou nome)
            if "microambiente" in tipo or "microambiente" in nome.lower():
                continue

            # ‚úÖ Arqu√©tipos - separar auto e equipe
            if "auto" in tipo:
                auto = conteudo
            elif "equipe" in tipo:
                equipe.append(conteudo)


        relatorio_final = {
            "empresa": empresa,
            "codrodada": codrodada,
            "emailLider": email_lider,
            "autoavaliacao": auto,
            "avaliacoesEquipe": equipe,
            "mensagem": "Relat√≥rio consolidado gerado com sucesso.",
            "caminho": f"Avaliacoes RH / {empresa} / {codrodada} / {email_lider}"
        }

        # üíæ Salva o novo JSON consolidado
        nome_arquivo = f"relatorio_consolidado_{email_lider}_{codrodada}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        conteudo = json.dumps(relatorio_final, ensure_ascii=False, indent=2).encode("utf-8")
        file_metadata = {"name": nome_arquivo, "parents": [lider_id]}
        media = MediaIoBaseUpload(io.BytesIO(conteudo), mimetype="application/json")
        service.files().create(body=file_metadata, media_body=media, fields="id").execute()

        return jsonify(relatorio_final)

    except Exception as e:
        return jsonify({"erro": str(e)}), 500






@app.route("/gerar-graficos-comparativos", methods=["POST", "OPTIONS"])
def gerar_graficos_comparativos():
    if request.method == "OPTIONS":
        response = jsonify({'status': 'CORS preflight OK'})
        response.headers["Access-Control-Allow-Origin"] = "https://gestor.thehrkey.tech"
        response.headers["Access-Control-Allow-Headers"] = "Content-Type,Authorization"
        response.headers["Access-Control-Allow-Methods"] = "GET,POST,OPTIONS"
        return response

    try:
        import requests
        from datetime import datetime

        dados = request.get_json()
        empresa = dados.get("empresa")
        codrodada = dados.get("codrodada")
        emailLider = dados.get("emailLider")
        print("üì• Dados recebidos:", empresa, codrodada, emailLider)

       

        headers = {
            "apikey": SUPABASE_KEY,
            "Authorization": f"Bearer {SUPABASE_KEY}",
            "Content-Type": "application/json"
        }

        filtro = f"?empresa=eq.{empresa}&codrodada=eq.{codrodada}&emaillider=eq.{emailLider}&select=dados_json"
        url = f"{SUPABASE_REST_URL}/consolidado_arquetipos{filtro}"
        print("üîé Buscando consolidado no Supabase:", url)

        resp = requests.get(url, headers=headers)
        registros = resp.json()

        if not registros or "dados_json" not in registros[0]:
            print("‚ùå Consolidado n√£o encontrado ou formato inv√°lido.")
            return jsonify({"erro": "Consolidado n√£o encontrado no Supabase."}), 404

        json_data = registros[0]["dados_json"]
        print("üìÑ Consolidado encontrado. Chaves:", list(json_data.keys()))

        percentuais_auto_result, percentuais_equipe_result, num_avaliacoes_result, dados_gerais_grafico = \
            gerar_grafico_completo_com_titulo(json_data, empresa, codrodada, emailLider)

        # AS VARI√ÅVEIS A SEGUIR J√Å EXISTEM NO SEU C√ìDIGO E T√äM OS VALORES CORRETOS:
        # - 'pct_auto' (seus Percentuais AUTO calculados)
        # - 'pct_equipes' (seus Percentuais EQUIPE calculados)
        # - 'len(respostas_equipes)' (o total de avalia√ß√µes da equipe)

        # Montando o dicion√°rio final para enviar ao frontend com os valores corretos
        json_para_frontend = {
            "titulo": dados_gerais_grafico["titulo"], # Pega do novo dicion√°rio
            "subtitulo": dados_gerais_grafico["subtitulo"], # Pega do novo dicion√°rio
            "info_avaliacoes": dados_gerais_grafico["info_avaliacoes"], # Pega do novo dicion√°rio
            "arquetipos": arquetipos, # Envia a lista de arqu√©tipos tamb√©m
            "autoavaliacao": percentuais_auto_result,    # Seus percentuais de autoavalia√ß√£o
            "mediaEquipe": percentuais_equipe_result,    # Seus percentuais da m√©dia da equipe
            "n_avaliacoes": num_avaliacoes_result        # A contagem de avalia√ß√µes
        }
    
        # Retornando o JSON completo para o navegador
        return jsonify(json_para_frontend), 200

    except Exception as e:
        print("üí• Erro geral na gera√ß√£o do gr√°fico:", str(e))
        return jsonify({"erro": str(e)}), 500


def gerar_grafico_completo_com_titulo(json_data, empresa, codrodada, emailLider):
    import numpy as np
    import matplotlib.pyplot as plt
    from matplotlib.backends.backend_pdf import PdfPages
    import tempfile
    from datetime import datetime
    import base64
    import requests

    respostas_auto = json_data.get("autoavaliacao", {}).get("respostas", {})
    respostas_equipes = [
        avaliacao.get("respostas", {}) for avaliacao in json_data.get("avaliacoesEquipe", [])
    ]
    
    # üîç Diagn√≥stico antes do c√°lculo
    print("üìÑ Chaves em respostas_auto:", respostas_auto.keys())
    print("üìÑ Q01 =", respostas_auto.get("Q01", "vazio"))
    if respostas_equipes:
        print("üìÑ Q01 (equipe) da 1¬™ pessoa =", respostas_equipes[0].get("Q01", "vazio"))
    
    # üìä C√°lculos
    pct_auto = calcular_percentuais(respostas_auto)
    pct_equipes = calcular_percentuais_equipes(respostas_equipes)
    
    # ‚úÖ Verifica√ß√£o final
    # Este bloco prepara os dados para o gr√°fico de barras (se voc√™ fosse gerar um no backend)
    # e tamb√©m para os t√≠tulos/subt√≠tulos do frontend.
    # Estamos mantendo ele aqui para organiza√ß√£o e como base para futuros desenvolvimentos
    # de relat√≥rios ou outros gr√°ficos que possam ser gerados no backend.

    # Dados para o t√≠tulo/subt√≠tulo e n√∫mero de avalia√ß√µes,
    # ser√£o usados no JSON final.
    dados_gerais_grafico = {
        "titulo": "ARQU√âTIPOS DE GEST√ÉO",
        "subtitulo": f"{emailLider} | {codrodada} | {empresa}",
        "info_avaliacoes": f"Equipe: {len(respostas_equipes)} respondentes"
    }
    return pct_auto, pct_equipes, len(respostas_equipes), dados_gerais_grafico

    fig, ax = plt.subplots(figsize=(10, 6))
    x = np.arange(len(arquetipos))
    auto_vals = [pct_auto.get(a, 0) for a in arquetipos]
    equipe_vals = [pct_equipes.get(a, 0) for a in arquetipos]

    ax.bar(x - 0.2, auto_vals, width=0.4, label="Autoavalia√ß√£o", color='royalblue')
    ax.bar(x + 0.2, equipe_vals, width=0.4, label="M√©dia da Equipe", color='darkorange')

    for i, (a, e) in enumerate(zip(auto_vals, equipe_vals)):
        ax.text(i - 0.2, a + 1, f"{a:.1f}%", ha='center', fontsize=9)
        ax.text(i + 0.2, e + 1, f"{e:.1f}%", ha='center', fontsize=9)

    ax.set_xticks(x)
    ax.set_xticklabels(arquetipos)
    ax.set_ylim(0, 100)
    ax.set_yticks(np.arange(0, 110, 10))
    ax.axhline(60, color='gray', linestyle='--', label="Dominante (60%)")
    ax.axhline(50, color='gray', linestyle=':', label="Suporte (50%)")
    ax.set_ylabel("Pontua√ß√£o (%)")
    ax.set_title(f"ARQU√âTIPOS DE GEST√ÉO\n{emailLider} | {codrodada} | {empresa}\nEquipe: {len(respostas_equipes)} respondentes", fontsize=12)
    ax.legend()
    plt.tight_layout()

    print("üì¶ Salvando PDF em mem√≥ria...")
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
        with PdfPages(tmp.name) as pdf:
            pdf.savefig(fig)

        with open(tmp.name, "rb") as f:
            pdf_base64 = base64.b64encode(f.read()).decode("utf-8")

    print("‚úÖ PDF convertido em base64 com sucesso.")

    # NOVO: Definindo os headers para a requisi√ß√£o POST
    headers = {
        "apikey": SUPABASE_KEY,
        "Authorization": f"Bearer {SUPABASE_KEY}",
        "Content-Type": "application/json"
    }
    nome_arquivo = f"ARQUETIPOS_AUTO_VS_EQUIPE_{emailLider}_{codrodada}.pdf"

    dados_ia = {
        "titulo": "ARQU√âTIPOS AUTOAVALIA√á√ÉO vs EQUIPE",
        "subtitulo": f"{empresa} / {emailLider} / {codrodada} / {datetime.now().strftime('%d/%m/%Y')}",
        "n_avaliacoes": len(respostas_equipes),
        "autoavaliacao": pct_auto,
        "mediaEquipe": pct_equipes
    }

    payload = {
        "empresa": empresa,
        "codrodada": codrodada,
        "emaillider": emailLider,
        "data_criacao": datetime.utcnow().isoformat(),
        "dados_json": dados_ia,
        "nome_arquivo": nome_arquivo,
        "arquivo_pdf_base64": pdf_base64
    }

    
    
    
    # Garante que as vari√°veis de ambiente est√£o sendo usadas
    # SUPABASE_REST_URL e SUPABASE_KEY j√° est√£o definidas globalmente no topo do arquivo.

    # Agora, DEFINA o dicion√°rio 'headers' imediatamente antes de us√°-lo na requisi√ß√£o POST.
    headers = {
        "apikey": SUPABASE_KEY,
        "Authorization": f"Bearer {SUPABASE_KEY}",
        "Content-Type": "application/json"
    }

    print("üì§ Enviando JSON + PDF para Supabase...")
    url_post = f"{SUPABASE_REST_URL}/consolidado_arquetipos"
    response = requests.post(url_post, headers=headers, json=payload)

    if response.status_code in [200, 201]:
        print("‚úÖ Envio finalizado com sucesso.")
    else:
        print(f"‚ùå Erro ao enviar para Supabase: {response.status_code} ‚Üí {response.text}")

    return jsonify(dados_ia), 200

@app.route("/ver-arquetipos")
def ver_arquetipos():
    return jsonify(arquetipos_dominantes)

from textwrap import wrap

def inserir_rodape(c, width, empresa, emailLider, codrodada):
    if c.getPageNumber() > 1:
        c.setFont("Helvetica", 8)
        rodape_y = 1.5 * cm
        info1 = f"Empresa: {empresa} | L√≠der: {emailLider} | Rodada: {codrodada}"
        info2 = datetime.now().strftime("%d/%m/%Y %H:%M")
        c.drawString(2 * cm, rodape_y, f"{info1} | {info2}")
        c.drawRightString(width - 2 * cm, rodape_y, f"P√°gina {c.getPageNumber() - 1}")


@app.route("/gerar-relatorio-analitico", methods=["POST"])
def gerar_relatorio_analitico():
    try:
        dados_requisicao = request.get_json()
        empresa = dados_requisicao.get("empresa")
        codrodada = dados_requisicao.get("codrodada")
        emailLider = dados_requisicao.get("emailLider")

        if not all([empresa, codrodada, emailLider]):
            return jsonify({"erro": "Campos obrigat√≥rios ausentes."}), 400

        # --- BUSCAR RELAT√ìRIO CONSOLIDADO DO SUPABASE ---
        if not SUPABASE_REST_URL or not SUPABASE_KEY:
            return jsonify({"erro": "Configura√ß√£o do Supabase ausente no servidor."}), 500

        # Ajuste o nome da tabela onde o relat√≥rio consolidado est√° salvo no Supabase
        supabase_url_consolidado = f"{SUPABASE_REST_URL}/consolidado_arquetipos" # Verifique se este √© o nome correto da sua tabela
        supabase_headers = {
            "apikey": SUPABASE_KEY,
            "Authorization": f"Bearer {SUPABASE_KEY}",
            "Content-Type": "application/json",
            "Accept": "application/json"
        }

        # Filtra por empresa, codrodada e emaillider (ajuste os nomes das colunas conforme seu Supabase)
        params_consolidado = {
            "empresa": f"eq.{empresa}",
            "codrodada": f"eq.{codrodada}",
            "emaillider": f"eq.{emailLider}"
        }
        
        # Faz a requisi√ß√£o GET para o Supabase
        print(f"DEBUG: Buscando relat√≥rio consolidado no Supabase para Empresa: {empresa}, Rodada: {codrodada}, L√≠der: {emailLider}")
        supabase_response = requests.get(supabase_url_consolidado, headers=supabase_headers, params=params_consolidado, timeout=30)
        supabase_response.raise_for_status() # Lan√ßa um erro para status HTTP ruins

        consolidated_data_list = supabase_response.json()

        if not consolidated_data_list:
            return jsonify({"erro": "Relat√≥rio consolidado n√£o encontrado no Supabase para os dados fornecidos."}), 404

        # Assume que o √∫ltimo registro √© o mais recente ou que s√≥ h√° um
        # Ou adicione l√≥gica para escolher o mais relevante se houver m√∫ltiplos
        relatorio_consolidado = consolidated_data_list[-1].get("dados_json", {})

        if not relatorio_consolidado:
            return jsonify({"erro": "Dados JSON do relat√≥rio consolidado vazios no Supabase para os dados fornecidos."}), 404

        auto = relatorio_consolidado.get("autoavaliacao", {})
        equipes = relatorio_consolidado.get("avaliacoesEquipe", [])

        respostas_auto = auto.get("respostas", {})
        respostas_equipes = [r.get("respostas", {}) for r in equipes if r.get("respostas")]

        # --- CARREGAR ARQUIVOS JSON E EXCEL LOCAIS ---
        # Certifique-se de que 'arquetipos_dominantes_por_questao.json' e 'TABELA_GERAL_ARQUETIPOS_COM_CHAVE.xlsx'
        # est√£o presentes no diret√≥rio raiz do seu projeto no Render.com.
        try:
            with open("arquetipos_dominantes_por_questao.json", encoding="utf-8") as f:
                mapa_dom = json.load(f)
            print("DEBUG: arquetipos_dominantes_por_questao.json carregado com sucesso.")
        except FileNotFoundError:
            return jsonify({"erro": "Arquivo 'arquetipos_dominantes_por_questao.json' n√£o encontrado no servidor."}), 500
        except json.JSONDecodeError:
            return jsonify({"erro": "Erro ao decodificar 'arquetipos_dominantes_por_questao.json'. Verifique o formato JSON."}), 500
        except Exception as e:
            return jsonify({"erro": f"Erro ao carregar 'arquetipos_dominantes_por_questao.json': {str(e)}"}), 500

        try:
            matriz_df = pd.read_excel("TABELA_GERAL_ARQUETIPOS_COM_CHAVE.xlsx")
            print("DEBUG: TABELA_GERAL_ARQUETIPOS_COM_CHAVE.xlsx carregada com sucesso.")
        except FileNotFoundError:
            return jsonify({"erro": "Arquivo 'TABELA_GERAL_ARQUETIPOS_COM_CHAVE.xlsx' n√£o encontrado no servidor."}), 500
        except Exception as e:
            return jsonify({"erro": f"Erro ao carregar 'TABELA_GERAL_ARQUETIPOS_COM_CHAVE.xlsx': {str(e)}"}), 500


        # Definir a lista de arqu√©tipos para a fun√ß√£o extrair_valor
        arquetipos_list_for_extrair_valor = set()
        for cod, dupla in mapa_dom.items():
            for arq in dupla:
                arquetipos_list_for_extrair_valor.add(arq)
        arquetipos_list_for_extrair_valor = sorted(list(arquetipos_list_for_extrair_valor))

        # Preparar dados para o frontend
        dados_gerados = {
            "titulo": "RELAT√ìRIO ANAL√çTICO ARQU√âTIPOS - POR QUEST√ÉO",
            "empresa": empresa,
            "codrodada": codrodada,
            "emailLider": emailLider,
            "n_avaliacoes": len(respostas_equipes), # N√∫mero de avalia√ß√µes da equipe
            "analitico": []
        }

        # Recriar a estrutura 'agrupado' para o agrupamento consistente no frontend
        agrupado_para_frontend = {}
        for cod_questao, duplas_arquetipos in mapa_dom.items():
            chave_grupo = " e ".join(sorted(duplas_arquetipos))
            if chave_grupo not in agrupado_para_frontend:
                agrupado_para_frontend[chave_grupo] = []
            agrupado_para_frontend[chave_grupo].append(cod_questao)

        # Iterar sobre as quest√µes agrupadas para popular 'analitico'
        for grupo, codigos in agrupado_para_frontend.items():
            for cod in codigos:
                info_auto = extrair_valor(matriz_df, cod, respostas_auto.get(cod), arquetipos_list_for_extrair_valor)
                
                somatorio = 0
                qtd_avaliacoes = 0
                for r in respostas_equipes:
                    try:
                        nota = int(round(float(r.get(cod, 0))))
                        if 1 <= nota <= 6:
                            somatorio += nota
                            qtd_avaliacoes += 1
                    except (ValueError, TypeError):
                        continue

                info_eq = None
                if qtd_avaliacoes > 0:
                    media = round(somatorio / qtd_avaliacoes)
                    info_eq = extrair_valor(matriz_df, cod, media, arquetipos_list_for_extrair_valor)

                # Incluir a quest√£o apenas se houver dados de autoavalia√ß√£o ou equipe
                if info_auto or info_eq:
                    dados_gerados["analitico"].append({
                        "grupoArquetipo": grupo, # Adicionado este campo para o agrupamento no frontend
                        "codigo": cod,
                        "afirmacao": (info_auto["afirmacao"] if info_auto else f"Afirma√ß√£o para {cod}"),
                        "autoavaliacao": {
                            "tendencia": info_auto["tendencia"] if info_auto else "-",
                            "percentual": info_auto["percentual"] if info_auto else 0
                        },
                        "mediaEquipe": {
                            "tendencia": info_eq["tendencia"] if info_eq else "-",
                            "percentual": info_eq["percentual"] if info_eq else 0
                        }
                    })
        
        # Chamar a NOVA fun√ß√£o para salvar os dados anal√≠ticos gerados no Supabase
        nome_arquivo_supabase = f"RELATORIO_ANALITICO_DADOS_{empresa}_{emailLider}_{codrodada}"
        salvar_relatorio_analitico_no_supabase(dados_gerados, empresa, codrodada, emailLider, nome_arquivo_supabase)

        # Retorna os dados gerados como JSON para o frontend
        return jsonify(dados_gerados), 200

    except requests.exceptions.RequestException as e:
        # Erros espec√≠ficos de requisi√ß√£o HTTP (Supabase)
        error_message = f"Erro de comunica√ß√£o com o Supabase: {str(e)}"
        detailed_traceback = traceback.format_exc()
        print(f"ERRO DE COMUNICA√á√ÉO SUPABASE: {error_message}")
        print(f"TRACEBACK COMPLETO:\n{detailed_traceback}")
        return jsonify({"erro": error_message, "traceback": detailed_traceback}), 500
    except FileNotFoundError as e:
        # Erros de arquivo n√£o encontrado
        error_message = f"Arquivo necess√°rio n√£o encontrado no servidor: {str(e)}"
        detailed_traceback = traceback.format_exc()
        print(f"ERRO DE ARQUIVO: {error_message}")
        print(f"TRACEBACK COMPLETO:\n{detailed_traceback}")
        return jsonify({"erro": error_message, "traceback": detailed_traceback}), 500
    except Exception as e:
        # Captura e retorna qualquer outro erro detalhado para depura√ß√£o no frontend
        error_message = str(e)
        detailed_traceback = traceback.format_exc()
        print(f"ERRO CR√çTICO NO BACKEND (GEN√âRICO): {error_message}")
        print(f"TRACEBACK COMPLETO:\n{detailed_traceback}")
        return jsonify({"erro": error_message, "traceback": detailed_traceback}), 500


def salvar_json_ia_no_drive(dados, nome_base, service, id_lider):
    try:
        from io import BytesIO
        import json
        from googleapiclient.http import MediaIoBaseUpload

        # Verifica (ou cria) subpasta ia_json
        def buscar_id(nome, pai):
            q = f"'{pai}' in parents and name='{nome}' and mimeType='application/vnd.google-apps.folder' and trashed=false"
            resp = service.files().list(q=q, fields="files(id)").execute().get("files", [])
            return resp[0]["id"] if resp else None

        id_pasta_ia = buscar_id("ia_json", id_lider)
        if not id_pasta_ia:
            pasta = service.files().create(
                body={"name": "ia_json", "mimeType": "application/vnd.google-apps.folder", "parents": [id_lider]},
                fields="id"
            ).execute()
            id_pasta_ia = pasta["id"]

        nome_arquivo = f"IA_{nome_base}.json"
        conteudo_bytes = BytesIO(json.dumps(dados, indent=2, ensure_ascii=False).encode("utf-8"))
        media = MediaIoBaseUpload(conteudo_bytes, mimetype="application/json")

        file_metadata = {"name": nome_arquivo, "parents": [id_pasta_ia]}
        service.files().create(body=file_metadata, media_body=media, fields="id").execute()

        print(f"‚úÖ JSON IA salvo no Drive: {nome_arquivo}")
    except Exception as e:
        print(f"‚ùå Erro ao salvar JSON IA: {str(e)}")




def salvar_json_ia_no_supabase(dados_ia, empresa, codrodada, emailLider, nome_arquivo):
    url = f"{SUPABASE_REST_URL}/consolidado_arquetipos"
    headers = {
        "Content-Type": "application/json",
        "apikey": SUPABASE_KEY,
        "Authorization": f"Bearer {SUPABASE_KEY}"
    }

    payload = {
        "empresa": empresa,
        "codrodada": codrodada,
        "emaillider": emailLider,
        "dados_json": dados_ia,
        "nome_arquivo": nome_arquivo,
        "data_criacao": datetime.now().isoformat()
    }

    response = requests.post(url, headers=headers, json=payload, timeout=30)
    if not response.ok:
        print("‚ùå Erro ao salvar no Supabase:", response.status_code, response.text)
    else:
        print("‚úÖ JSON do gr√°fico salvo no Supabase com sucesso.")


# --- NOVA FUN√á√ÉO PARA SALVAR O RELAT√ìRIO ANAL√çTICO NO SUPABASE ---
# Mantenha sua fun√ß√£o 'salvar_json_ia_no_supabase' existente intacta.
# Esta nova fun√ß√£o ser√° usada APENAS para o Relat√≥rio Anal√≠tico.
def salvar_relatorio_analitico_no_supabase(dados_ia, empresa, codrodada, emailLider, nome_arquivo):
    """
    Salva os dados gerados do relat√≥rio anal√≠tico no Supabase.
    """
    if not SUPABASE_REST_URL or not SUPABASE_KEY:
        print("‚ùå N√£o foi poss√≠vel salvar o relat√≥rio anal√≠tico no Supabase: Vari√°veis de ambiente n√£o configuradas.")
        return

    # Ajuste o nome da tabela no Supabase se for diferente.
    # Esta tabela deve ser para os dados do relat√≥rio anal√≠tico por quest√£o.
    url = f"{SUPABASE_REST_URL}/relatorios_analiticos_hrkey" # Sugest√£o de nome de tabela
    headers = {
        "Content-Type": "application/json",
        "apikey": SUPABASE_KEY,
        "Authorization": f"Bearer {SUPABASE_KEY}" # Use a chave de servi√ßo para escrita se for o caso
    }

    payload = {
        "empresa": empresa,
        "codrodada": codrodada,
        "emaillider": emailLider,
        "dados_json": dados_ia, # Os dados JSON completos do relat√≥rio anal√≠tico
        "nome_arquivo": nome_arquivo,
        "data_criacao": datetime.now().isoformat()
    }

    try:
        response = requests.post(url, headers=headers, json=payload, timeout=30)
        response.raise_for_status() # Lan√ßa um erro para status de resposta HTTP ruins (4xx ou 5xx)
        print("‚úÖ JSON do relat√≥rio anal√≠tico salvo no Supabase com sucesso.")
    except requests.exceptions.RequestException as e:
        print(f"‚ùå Erro ao salvar JSON do relat√≥rio anal√≠tico no Supabase: {e}")
        if hasattr(response, 'status_code') and hasattr(response, 'text'):
            print(f"Detalhes da resposta do Supabase: Status {response.status_code} - {response.text}")
        else:
            print("N√£o foi poss√≠vel obter detalhes da resposta do Supabase.")

# --- EXECU√á√ÉO DO FLASK APP ---
if __name__ == "__main__":
    app.run(host='0.0.0.0', port=os.environ.get('PORT', 5000))

